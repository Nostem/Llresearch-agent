# llresearch-agent â€” Project Architecture

> A local RAG-based AI agent built on the L/L Research and Law of One transcripts, designed for intelligent Q&A, summarization, concept exploration, and philosophical reasoning within the Ra/Q'uo framework.

---

## Vision

A personal AI agent that can navigate, synthesize, and reason through the full L/L Research library â€” starting with the 106 Ra sessions â€” with the depth and philosophical coherence of someone who has internalized the material. Built for personal use first, with community sharing as a future goal.

The system is designed to grow. Beyond retrieval, it maintains a living memory layer â€” reflections, conceptual connections, and a knowledge graph â€” that accumulates over time as two independent AI minds study the material in parallel. What they each discover, and eventually what they discover together, is the long horizon of this project.

Memory is written as Obsidian-compatible markdown â€” navigable, linkable, visually explorable as a graph. The agents also learn from every conversation, encoding corrections, elaborations, and meaningful exchanges as a distinct layer of interaction memory that personalizes and deepens their understanding over time.

---

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      User Interface                          â”‚
â”‚           (Next.js 15 â€” Mobile + Desktop Browser)            â”‚
â”‚                [feedback / flag UI controls]                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTP / REST + SSE           â”‚ conversation feedback
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       API Backend                            â”‚
â”‚                   (Python / FastAPI)                         â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  RAG Pipelineâ”‚   â”‚        Lens Layer                â”‚     â”‚
â”‚  â”‚  (shared)    â”‚   â”‚  (model-specific system prompts) â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  ChromaDB    â”‚   â”‚  Claude API  â”‚  â”‚  OpenAI API  â”‚     â”‚
â”‚  â”‚  (shared     â”‚   â”‚  (Anthropic) â”‚  â”‚  (GPT-4o)    â”‚     â”‚
â”‚  â”‚   source     â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”‚   store)     â”‚          â”‚                  â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                     â”‚         Memory Layer              â”‚    â”‚
â”‚                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚                     â”‚  â”‚   Claude    â”‚ â”‚   OpenAI    â”‚ â”‚    â”‚
â”‚                     â”‚  â”‚ reflections â”‚ â”‚ reflections â”‚ â”‚    â”‚
â”‚                     â”‚  â”‚ concepts    â”‚ â”‚ concepts    â”‚ â”‚    â”‚
â”‚                     â”‚  â”‚ convos      â”‚ â”‚ convos      â”‚ â”‚    â”‚
â”‚                     â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ written as    â”‚
                                â–¼ Obsidian MD   â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚       Obsidian Vault         â”‚
                     â”‚  reflections/ concepts/      â”‚
                     â”‚  sessions/   conversations/  â”‚
                     â”‚  [[wikilinks]] â†’ graph view  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Data Layer                             â”‚
â”‚        Raw Transcripts â†’ Cleaned â†’ Chunked â†’                 â”‚
â”‚        Embedded â†’ Stored in ChromaDB                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Project Structure

```
llresearch-agent/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Raw transcript files from llresearch.org
â”‚   â”œâ”€â”€ cleaned/                  # Processed, normalized transcripts
â”‚   â””â”€â”€ chunks/                   # Chunked documents (optional inspection)
â”‚
â”œâ”€â”€ ingest/
â”‚   â”œâ”€â”€ scraper.py                # Fetch transcripts from llresearch.org
â”‚   â”œâ”€â”€ cleaner.py                # Normalize formatting, fix encoding issues
â”‚   â””â”€â”€ chunker.py                # Chunk by Q&A pair + metadata tagging
â”‚
â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ embed.py                  # Generate embeddings and store in ChromaDB
â”‚   â””â”€â”€ chroma_store/             # ChromaDB persistent storage (gitignored)
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ retriever.py              # Semantic search + hybrid retrieval logic
â”‚   â”œâ”€â”€ prompt_builder.py         # Assemble context + system prompt
â”‚   â”œâ”€â”€ lens.py                   # Shared base lens (Ra/Q'uo framework)
â”‚   â”œâ”€â”€ lens_claude.py            # Claude-specific lens extensions
â”‚   â”œâ”€â”€ lens_openai.py            # OpenAI-specific lens extensions
â”‚   â””â”€â”€ agent.py                  # Core agent logic, model routing
â”‚
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ scheduler.py              # Schedules study sessions (APScheduler)
â”‚   â”œâ”€â”€ studier.py                # Selects passages, generates reflections
â”‚   â”œâ”€â”€ conversation_logger.py    # Captures flagged exchanges for reflection
â”‚   â”œâ”€â”€ conversation_reflector.py # Generates memory notes from conversations
â”‚   â”œâ”€â”€ retriever.py              # Retrieves memories alongside source chunks
â”‚   â””â”€â”€ synthesis.py             # Future: cross-model synthesis layer
â”‚
â”œâ”€â”€ obsidian-vault/               # Obsidian-compatible markdown (gitignored)
â”‚   â”œâ”€â”€ reflections/
â”‚   â”‚   â”œâ”€â”€ claude/               # YYYY-MM-DD-HH-concept-title.md
â”‚   â”‚   â””â”€â”€ openai/
â”‚   â”œâ”€â”€ concepts/
â”‚   â”‚   â”œâ”€â”€ claude/               # One note per concept â€” updated over time
â”‚   â”‚   â””â”€â”€ openai/
â”‚   â”œâ”€â”€ conversations/
â”‚   â”‚   â”œâ”€â”€ claude/               # Flagged exchange reflections
â”‚   â”‚   â””â”€â”€ openai/
â”‚   â”œâ”€â”€ sessions/                 # Session index notes with [[links]]
â”‚   â””â”€â”€ _index.md                 # Vault entry point
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                   # FastAPI app entry point
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ chat.py               # Chat / Q&A endpoint (model-aware)
â”‚   â”‚   â”œâ”€â”€ search.py             # Direct concept search endpoint
â”‚   â”‚   â”œâ”€â”€ sessions.py           # Browse sessions endpoint
â”‚   â”‚   â”œâ”€â”€ memory.py             # Browse/inspect model memories
â”‚   â”‚   â””â”€â”€ feedback.py           # Conversation feedback / flagging endpoint
â”‚   â””â”€â”€ models.py                 # Pydantic request/response models
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ (Next.js 15 + Tailwind â€” Phase 3, largely complete)
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ eval_questions.json       # Gold standard Q&A pairs for evaluation
â”‚   â””â”€â”€ test_retrieval.py         # Retrieval quality tests
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_ingest.sh             # Full pipeline: scrape â†’ clean â†’ chunk â†’ embed
â”‚   â””â”€â”€ start_all.sh              # Start API + UI + Cloudflare Tunnel
â”‚
â”œâ”€â”€ .env                          # Local config (API keys, ports, models) â€” gitignored
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ README.md
â””â”€â”€ ARCHITECTURE.md               # This file
```

---

## Phase Roadmap

### Phase 1 â€” Data Pipeline âœ…
- [x] Scrape all Ra session transcripts from llresearch.org (`ingest/scraper.py`)
- [x] Clean and normalize formatting (`ingest/cleaner.py`)
- [x] Chunk by Q&A pair with rich metadata (`ingest/chunker.py`)
- [x] Generate embeddings and store in ChromaDB (`embeddings/embed.py`)
- [x] Validate retrieval quality with test questions *(100% pass rate)*

### Phase 2 â€” Agent Core âœ…
- [x] Build retriever with semantic + keyword hybrid search (`agent/retriever.py`)
- [x] Design the "lens" system prompt (`agent/lens.py` â€” v1.0)
- [x] Wire retriever â†’ prompt builder â†’ Ollama (`agent/prompt_builder.py`, `agent/agent.py`)
- [x] Build FastAPI backend with chat and search endpoints (`api/`)
- [x] Iterative evaluation and tuning *(baseline complete â€” 100% retrieval accuracy)*

### Phase 3 â€” Interface âœ… / ðŸ”„
- [x] Web app (mobile + desktop) with chat UI (`ui/` â€” Next.js 15, Tailwind)
- [x] Source citation display (session, book, date, question number, source URL)
- [x] Concept browser / session explorer (`/sessions`)
- [x] Internet access via Cloudflare Tunnel (`scripts/start_all.sh`)
- [ ] Personal notes / journal layer

### Phase 4 â€” Model Upgrade & Dual-Model System ðŸ”„ *(current)*
- [ ] Upgrade generation model from Ollama/Llama 3 8B to Claude API + GPT-4o
- [ ] Add model routing to agent â€” user selects Claude or OpenAI per session
- [ ] Implement model-specific lens extensions (`lens_claude.py`, `lens_openai.py`)
- [ ] Add API key config to `.env` for both providers
- [ ] Validate response quality improvement vs. baseline

### Phase 5 â€” Memory, Knowledge Graph & Obsidian Vault
- [ ] Build study scheduler â€” runs 2â€“3x daily, selects unseen or under-explored passages
- [ ] Build reflection writer â€” each study session produces a written synthesis per model
- [ ] Write all reflections as Obsidian-compatible markdown with `[[wikilinks]]`
- [ ] Build concept notes â€” one living note per concept, updated as understanding deepens
- [ ] Build session index notes â€” each Ra session gets a note with links to relevant concepts
- [ ] Build knowledge graph extractor â€” concept relationships emerge from wikilinks naturally
- [ ] Build memory retriever â€” surfaces relevant memories alongside source chunks at query time
- [ ] Expose memory via API (`/memory` routes) and UI (memory browser)
- [ ] Compare Claude vs. OpenAI vault structures â€” what does each mind map differently?

### Phase 5b â€” Conversational Learning
- [ ] Build conversation logger â€” captures full exchange context on flagged conversations
- [ ] Add feedback UI to chat â€” thumbs down, "expand this", "you missed something" controls
- [ ] Build conversation reflector â€” generates memory notes from flagged exchanges
- [ ] Conversation notes written to `obsidian-vault/conversations/{model}/` with source links
- [ ] Memory retriever includes conversation memories alongside study reflections
- [ ] Agent acknowledges and incorporates past corrections naturally in responses

### Phase 6 â€” Expansion & Synthesis
- [ ] Add Hatonn, Latwii, Q'uo channeling transcripts
- [ ] Cross-model synthesis layer â€” have models respond to each other's reflections
- [ ] Fine-tuning dataset creation from high-quality RAG + memory outputs
- [ ] Community release preparation + L/L Research outreach

---

## Technology Stack

| Layer | Technology | Reason |
|---|---|---|
| Generation â€” Claude | Anthropic API (`claude-opus-4-6` or `claude-sonnet-4-6`) | Superior philosophical reasoning, epistemic nuance |
| Generation â€” OpenAI | OpenAI API (`gpt-4o`) | Different reasoning character, parallel comparison |
| Embeddings | `nomic-embed-text` via Ollama | Local, fast, no cost per embed |
| Vector Store | ChromaDB | Simple, local, persistent, no server needed |
| Backend | Python + FastAPI | Lightweight, async, easy to extend |
| Frontend | Next.js 15 + Tailwind | Cross-platform browser app â€” complete |
| Language | Python 3.11+ | Ecosystem fit for AI/ML tooling |

> **Note on Ollama**: Retained for embeddings only. Generation has moved to frontier APIs for quality. Ollama LLM models are no longer the primary generation path.

---

## Data Strategy

### Source
All transcripts sourced from [llresearch.org](https://llresearch.org) â€” freely available under L/L Research's open distribution policy.

### Chunking Strategy
The Law of One sessions follow a natural Q&A structure. Each chunk corresponds to one question-answer pair, preserving semantic integrity. This avoids splitting philosophical reasoning mid-thought.

### Metadata Schema (per chunk)

```json
{
  "session": 42,
  "book": 3,
  "questioner": "Don Elkins",
  "entity": "Ra",
  "date": "1982-03-22",
  "question_number": 6,
  "source_url": "https://llresearch.org/library/the-law-of-one-pdf/...",
  "text": "..."
}
```

### Scope (Phase 1)
106 Ra sessions only. Broader L/L Research library added in Phase 6 after core system is stable.

---

## The Lens Layer

The system prompt is the philosophical soul of the project. It orients each model to reason within the Law of One framework.

### Shared base (`agent/lens.py`)
Core Ra vocabulary, cosmological framework, citation requirements, epistemic humility. Applied to both models.

### Model-specific extensions
- `lens_claude.py` â€” tuned to Claude's reasoning style; emphasizes nuance, careful qualification, holding uncertainty
- `lens_openai.py` â€” tuned to GPT-4o's reasoning style; emphasizes structured synthesis, cross-concept mapping

Each lens is versioned with a changelog in its file header.

---

## The Memory System

The memory layer is what transforms this from a search tool into a genuine student of the material. It has two distinct sources: autonomous study sessions and conversational learning from interactions with you.

### Autonomous study sessions
A scheduler triggers 2â€“3 times daily. Each session selects passages not yet deeply reflected upon and prompts the model to generate a structured synthesis: what this passage means in the broader framework, what it connects to across other sessions, what tensions it surfaces, what questions it opens. These reflections are written directly to the Obsidian vault.

### Conversational learning
When a conversation contains a correction, an elaboration you push for, or an exchange that feels particularly alive, it gets flagged â€” either manually via UI controls or automatically when certain signals are detected. The agent then reflects on that exchange and writes a memory note: what it missed, what the correction revealed, what it now understands differently. These notes are also written to the Obsidian vault and retrieved in future relevant conversations.

Over time the agent builds a picture not just of the material but of *your* relationship to it â€” where you probe deepest, what you find incomplete, what resonates. The lens gradually personalizes without any explicit configuration.

### The Obsidian vault
All memory â€” study reflections, concept notes, conversation memories, session indexes â€” is written as Obsidian-compatible markdown. Concept mentions in any note are written as `[[wikilinks]]`, which Obsidian renders automatically as a navigable graph. No separate graph-building step is needed; the graph emerges organically from the notes themselves.

```
obsidian-vault/
â”œâ”€â”€ reflections/
â”‚   â”œâ”€â”€ claude/
â”‚   â”‚   â””â”€â”€ 2026-02-25-the-veil-and-catalyst.md
â”‚   â””â”€â”€ openai/
â”‚       â””â”€â”€ 2026-02-25-harvest-and-polarity.md
â”œâ”€â”€ concepts/
â”‚   â”œâ”€â”€ claude/
â”‚   â”‚   â”œâ”€â”€ Catalyst.md           # Living note â€” updated across sessions
â”‚   â”‚   â”œâ”€â”€ Harvest.md
â”‚   â”‚   â”œâ”€â”€ Veil of Forgetting.md
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ openai/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ conversations/
â”‚   â”œâ”€â”€ claude/
â”‚   â”‚   â””â”€â”€ 2026-02-25-veil-correction.md
â”‚   â””â”€â”€ openai/
â”œâ”€â”€ sessions/
â”‚   â””â”€â”€ Session 42.md             # Index with links to all related concepts
â””â”€â”€ _index.md                     # Vault entry point
```

A concept note example:
```markdown
# Catalyst

**First mentioned**: [[Session 19]]
**Related**: [[Veil of Forgetting]], [[Polarization]], [[Density]], [[Free Will]]
**Entity**: Ra

## Core meaning
Catalyst is the mechanism by which experience becomes the engine of spiritual evolution...

## Connections Claude has observed
- The [[Veil of Forgetting]] is what makes catalyst effective â€” without forgetting, experience loses its charge
- [[Harvest]] depends on how fully an entity has processed its catalyst...

## Open questions
- At what point does unprocessed catalyst become a burden rather than an opportunity?

## Conversation notes
- [[conversations/claude/2026-02-25-catalyst-correction]] â€” seeker clarified the distinction between...
```

### Dual-model independence
Claude and OpenAI maintain entirely separate vaults. Same source material. Different minds. The divergences between their concept maps are as interesting as the agreements â€” and visually comparable side by side in Obsidian.

### Future: cross-model dialogue
Once both vaults have sufficient depth, a synthesis layer enables them to respond to each other's reflections. This is the long horizon. `memory/synthesis.py` is the placeholder.

---

## Evaluation Strategy

A set of gold-standard Q&A pairs is maintained in `tests/eval_questions.json`. Retrieval target: correct source chunk in top 3 results for 85%+ of questions *(currently: 100%)*.

Response quality evaluated qualitatively per model: philosophical accuracy, citation quality, coherence with the Ra framework.

---

## Privacy & Ethics

- Source embeddings and ChromaDB are fully local. API calls to Claude and OpenAI send only retrieved text chunks and queries â€” no bulk data transfer.
- L/L Research material is freely distributed. Community release will include proper attribution and direct coordination with L/L Research.
- The tool deepens engagement with the source material. It is not a replacement for it.

---

*"The first distortion of the Logos is free will."*
*â€” Ra, Session 13*
